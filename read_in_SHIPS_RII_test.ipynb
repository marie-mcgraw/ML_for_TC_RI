{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4097ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "# from google.colab import drive\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae4cc5",
   "metadata": {},
   "source": [
    "#### Get list of all files for desired year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0d2db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_sel = 2021\n",
    "fdir = '/mnt/tcnas01/musgrave/ryan_ridata/oper_stext/{yr_sel}/'.format(yr_sel=yr_sel)\n",
    "#fname_test = '20072600AL9220_ships.txt'\n",
    "all_files = glob.glob(fdir+'*.txt')\n",
    "no_files = len(all_files)\n",
    "fname_test = all_files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ab2ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afb3f412",
   "metadata": {},
   "source": [
    "#### Read in each file one at a time\n",
    "\n",
    "Relevant information:\n",
    "* TIME\n",
    "* LAND (KM)\n",
    "* Prob of RI for 25 kt RI threshold\n",
    "* Prob of RI for 30 kt RI threshold\n",
    "* Prob of RI for 35 kt RI threshold\n",
    "* LAT (DEG N)\n",
    "* LONG (DEG W)\n",
    "* Name\n",
    "* Case No.\n",
    "* DATE\n",
    "* TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ae8778",
   "metadata": {},
   "source": [
    "#### Create ultimate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3898b993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test_lines\n",
    "# case = test_lines[3].split()[2]\n",
    "# date = test_lines[3].split()[3]\n",
    "# name = test_lines[3].split()[1]\n",
    "#start_time = test_lines[3].split()[4]\n",
    "#for line in test_lines:\n",
    " #   if line.startswith('LAND (KM)'):\n",
    "  #      print(line.split()[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "724dc300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/tcnas01/musgrave/ryan_ridata/oper_stext/2021/21021712AL8521_ships.txt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf743fa8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME (HR)          0     6    12    18    24    36    48    60    72    84    96   108   120   132   144   156   168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(fname_test) as fn:\n",
    "    for line in fn:\n",
    "        if line.startswith(\"TIME (HR)\"):\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed1e3ded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SAT'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(fname_test).readlines()[2].split()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0419c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RI_prob_df_ALL = pd.DataFrame()\n",
    "##\n",
    "#no_files = \n",
    "#for ifile in np.arange(0,no_files-1):\n",
    "ifile = 48\n",
    "fname_test = all_files[ifile]\n",
    "file_test = open(fname_test)\n",
    "test_lines = file_test.readlines()\n",
    "#test_lines[1].split()\n",
    "#basin_from_filename = fname_test[58:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31740ef",
   "metadata": {},
   "source": [
    "##### Info we need\n",
    "* ATCF ID: line after IR SAT\n",
    "* DATE: line after IR SAT\n",
    "* INIT TIME: line after IR SAT\n",
    "* TIME: line starts with 'TIME\n",
    "* STORM TYPE: line starts with Storm\n",
    "* LAND: line starts with LAND\n",
    "* LAT: line starts with LAT\n",
    "* LON: line starts with LON\n",
    "* VMAX: line starts with 'V (kt) NO LAND\n",
    "* SHIPS-RII probs: line starts with SHIPS-RII\n",
    "* SHIPS consensus probs: line starts with CONSENSUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5013c25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x file has been opened /mnt/tcnas01/musgrave/ryan_ridata/oper_stext/2021/21020212AL8321_ships.txt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3496803/1485575667.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m          \u001b[0;31m#   continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdf_forecast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TIME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "df_forecast = pd.DataFrame(columns=['TIME','Storm Type','DTL','LAT','LON','ATCF ID','DATE','Init Time','VMAX',\n",
    "                                   'RI Type','Pr(30/24)'])\n",
    "RI_type = '   SHIPS-RII'\n",
    "for x in np.arange(0,len(all_files)):\n",
    "    x_file = open(all_files[x]).readlines()\n",
    "    print('x file has been opened',all_files[x])\n",
    "    df_fore_ALL = pd.DataFrame()\n",
    "    for i in np.arange(0,len(x_file)):\n",
    "\n",
    "        #i = 88\n",
    "        iline = test_lines[i]\n",
    "        #print(i)\n",
    "        if iline.startswith('                                 *                  GFS version                   *\\n'):\n",
    "            continue\n",
    "        if iline.startswith('                                 * IR SAT'):\n",
    "            atcf_id = test_lines[i+1].split()[2]\n",
    "            date = test_lines[i+1].split()[3]\n",
    "            init_time = test_lines[i+1].split()[4]\n",
    "            print(test_lines[i+1].split())\n",
    "        if iline.startswith('TIME (HR)'):\n",
    "            time = iline\n",
    "            vmax = test_lines[i+1].split()[4]\n",
    "            #print(time)\n",
    "        #else:\n",
    "         #   continue\n",
    "        #\n",
    "        df_forecast['TIME'] = time.split()[2:]\n",
    "        ## \n",
    "        #\n",
    "        if iline.startswith('Storm Type'):\n",
    "            storm_type = iline\n",
    "        df_forecast['Storm Type'] = storm_type.split()[2:]\n",
    "        if iline.startswith('LAND'):\n",
    "            DTL = iline\n",
    "        df_forecast['DTL'] = DTL.split()[2:]\n",
    "        if iline.startswith('LAT'):\n",
    "            lat = iline\n",
    "        if iline.startswith('LON'):\n",
    "            lon = iline\n",
    "        #\n",
    "        df_forecast['LAT'] = lat.split()[3:]\n",
    "        df_forecast['LON'] = lon.split()[2:]\n",
    "        df_forecast['ATCF ID'] = atcf_id\n",
    "        df_forecast['DATE'] = date\n",
    "        df_forecast['Init Time'] = init_time\n",
    "\n",
    "        df_forecast['VMAX'] = vmax\n",
    "        ## \n",
    "        # df_fore_copy = df_forecast.copy()\n",
    "        ##\n",
    "        if test_lines[i].startswith('Matrix'):\n",
    "           # xxx = test_lines[iline+3]\n",
    "            xxx = test_lines[i+4].split()[3][0:4]\n",
    "           # print(RI_30_24)\n",
    "            #RI_type = RI_type\n",
    "            # print(RI_type)\n",
    "        #print(xxx)\n",
    "        #print(RI_30_24)\n",
    "        #print(xxx)\n",
    "        df_forecast['RI Type'] = 'SHIPS-RII'\n",
    "        df_forecast['Pr(30/24)'] = xxx\n",
    "    df_fore_ALL = df_fore_ALL.append(df_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c51fc7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                 * ATLANTIC     2020 SHIPS INTENSITY FORECAST     *\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b73ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lines[88].startswith('Matrix')\n",
    "#np.array(test_lines[92].split()[3][0:4])\n",
    "#df_forecast\n",
    "#rint(test_lines[88].split())#[3][0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb7624c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if yr_sel == 2021:\n",
    "    line_no_vec = [1,3,90,92,95]\n",
    "elif yr_sel == 2020:\n",
    "    line_no_vec = [1,3,90,91]#,95]\n",
    "# Check formatting\n",
    "\n",
    "# Check if extratropical\n",
    "if np.isin('EXTP',test_lines[9].split()[0:7]):\n",
    "    print('Extratropical')\n",
    "    continue\n",
    "#else:\n",
    " #   print('We good')\n",
    "# Check if stays away from land\n",
    "if test_lines[25].split()[0] == 'LAND':\n",
    "    DTL_str = test_lines[25].split()[2:7]\n",
    "    lat_str = test_lines[26].split()[3:8]\n",
    "    lon_str = test_lines[27].split()[3:8]\n",
    "    if np.isin('N/A',DTL_str):\n",
    "        print('too close to land')\n",
    "        continue\n",
    "    else:\n",
    "        DTL = [int(i) for i in DTL_str]\n",
    "        #fname_test\n",
    "        if all(x > 100 for x in DTL):\n",
    "            print('sufficiently far from land')\n",
    "        else:\n",
    "            print('too close to land')\n",
    "            continue\n",
    "elif test_lines[25].split()[0] == 'LAT':\n",
    "    DTL_str = test_lines[24].split()[2:7]\n",
    "    lat_str = test_lines[25].split()[3:8]\n",
    "    lon_str = test_lines[26].split()[3:8]\n",
    "    if np.isin('N/A',DTL_str):\n",
    "        print('too close to land')\n",
    "        continue\n",
    "    else:\n",
    "        DTL = [int(i) for i in DTL_str]\n",
    "        #fname_test\n",
    "        if all(x > 100 for x in DTL):\n",
    "            print('sufficiently far from land')\n",
    "        else:\n",
    "            print('too close to land')\n",
    "            continue\n",
    "elif test_lines[25].split()[0] == 'LONG':\n",
    "    DTL_str = test_lines[23].split()[2:7]\n",
    "    lat_str = test_lines[24].split()[3:8]\n",
    "    lon_str = test_lines[25].split()[3:8]\n",
    "    if np.isin('N/A',DTL_str):\n",
    "        print('too close to land')\n",
    "        continue\n",
    "    else:\n",
    "        DTL = [int(i) for i in DTL_str]\n",
    "        #fname_test\n",
    "        if all(x > 100 for x in DTL):\n",
    "            print('sufficiently far from land')\n",
    "        else:\n",
    "            print('too close to land')\n",
    "            continue\n",
    "#print(basin_from_filename)\n",
    "\n",
    "if test_lines[0].split()[1]  != 'GFS':\n",
    "    line_no_use = [x - 1 for x in line_no_vec]\n",
    "    print('formatting change :-/')\n",
    "else:\n",
    "    line_no_use = line_no_vec\n",
    "    #print('normal format')\n",
    "# Line 1 of each file contains information about BASIN, YEAR\n",
    "if basin_from_filename == 'AL':\n",
    "    basin = test_lines[line_no_use[0]].split()[1]\n",
    "else:\n",
    "    basin = test_lines[line_no_use[0]].split()[1:3]\n",
    "## \n",
    "year = test_lines[line_no_use[0]].split()[2]\n",
    "atcf_id = test_lines[3].split()[2]\n",
    "# Line 3 of each file contains information about case, date, time\n",
    "case = test_lines[line_no_use[1]].split()[2]\n",
    "name = test_lines[line_no_use[1]].split()[1]\n",
    "if len(test_lines[line_no_use[1]].split()) == 7:\n",
    "    date = test_lines[line_no_use[1]].split()[3]\n",
    "else:\n",
    "    date = test_lines[line_no_use[1]+1].split()[3]\n",
    "time = test_lines[line_no_use[1]].split()[4]\n",
    "\n",
    "# RI probability headers are in lines 90\n",
    "if len(test_lines[line_no_use[2]].split()) < 18:\n",
    "    line_no_use[2] = line_no_use[2] - 1\n",
    "RI_prob_header = test_lines[line_no_use[2]].split()\n",
    "if test_lines[line_no_use[3]].split()[0] == 'Logistic:':\n",
    "    SHIPS_RII = test_lines[line_no_use[3]-1].split()\n",
    "elif test_lines[line_no_use[3]].split()[0] != 'SHIPS-RII:':\n",
    "    SHIPS_RII = test_lines[line_no_use[3]+1].split()\n",
    "else:\n",
    "    SHIPS_RII = test_lines[line_no_use[3]].split()\n",
    "######\n",
    "if yr_sel != 2021:\n",
    "    if test_lines[line_no_use[4]].split()[0] == 'DTOPS:':\n",
    "        SHIPS_consensus = test_lines[line_no_use[4]-1].split()\n",
    "    else:\n",
    "        SHIPS_consensus = test_lines[line_no_use[4]-1].split()\n",
    "else:\n",
    "    SHIPS_consensus = np.empty(9)\n",
    "    SHIPS_consensus[:] = np.nan\n",
    "\n",
    "# Make dataframe\n",
    "RI_prob_df = pd.DataFrame(columns={RI_prob_header[5],RI_prob_header[7],\n",
    "                                  RI_prob_header[9],RI_prob_header[11],RI_prob_header[13],RI_prob_header[15],\n",
    "                                  RI_prob_header[17],RI_prob_header[18]},index={'RII','Consensus'})\n",
    "RI_prob_df = RI_prob_df.rename(columns={'|65/72':'65/72'})\n",
    "RI_probs_list = RI_prob_df.columns\n",
    "RI_prob_df = RI_prob_df.reindex(columns=sorted(RI_prob_df.columns))\n",
    "RI_prob_df.loc['RII'] = SHIPS_RII[1::]\n",
    "RI_prob_df.loc['Consensus'] = SHIPS_consensus[1::]\n",
    "\n",
    "# Add case info\n",
    "if basin_from_filename == 'EP':\n",
    "    RI_prob_df['BASIN'] = basin[0]+'_'+basin[1]\n",
    "elif basin_from_filename == 'CP':\n",
    "    RI_prob_df['BASIN'] = 'CENTRAL_PACIFIC'\n",
    "else:\n",
    "    RI_prob_df['BASIN'] = basin\n",
    "RI_prob_df['Date'] = pd.to_datetime(date)\n",
    "RI_prob_df['ATCF ID'] = atcf_id\n",
    "RI_prob_df['NAME'] = name\n",
    "RI_prob_df['Time (hr)'] = time\n",
    "RI_prob_df['CASE'] = case\n",
    "RI_prob_df['LAT_0'] = np.float(lat_str[0]) if lat_str[0] != 'xxx.x' else np.nan\n",
    "RI_prob_df['LON_0'] = np.float(lon_str[0]) if lon_str[0] != 'xxx.x' else np.nan\n",
    "RI_prob_df_ALL = RI_prob_df_ALL.append(RI_prob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c8f2b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_lines#[70].split()\n",
    "test_lines#[line_no_use[4]].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b685d804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "foo = np.float(lon_str[0]) if lon_str[0] != 'xxx.x' else np.nan\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RI_prob_df_save = RI_prob_df_ALL.reset_index().rename(columns={'index':'RI Type'})\n",
    "for icol in RI_probs_list:\n",
    "    RI_prob_df_save[icol] = RI_prob_df_save[icol].str[:-1].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7525db",
   "metadata": {},
   "outputs": [],
   "source": [
    "RI_prob_df_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077361c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RI_prob_df_save['Time (hr)'] = RI_prob_df_save['Time (hr)'].astype(int)\n",
    "RI_prob_df_save['Time (TD)'] = pd.to_timedelta(RI_prob_df_save['Time (hr)'],unit='h')\n",
    "#RI_prob_df_save_tr = RI_prob_df_save.where(RI_prob_df_save['20/12']<999.0).dropna(how='all')\n",
    "#len(RI_prob_df_save_tr)\n",
    "RI_prob_df_save['Time (TD)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffa657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datetime as dt\n",
    "RI_prob_df_save['DATE_full'] = pd.to_datetime(RI_prob_df_save['Date']+RI_prob_df_save['Time (TD)']\n",
    "                     ,format='%Y-%m-%d%H')\n",
    "#RI_prob_df_save['Time (hr)']\n",
    "#RI_prob_df_save['Date']\n",
    "RI_prob_df_save['DATE_full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7554314d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "RI_prob_df_save.groupby(['BASIN','RI Type']).count()#.xs(('ATLANTIC','2020-09-14 12:00:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0935ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig1,ax1 = plt.subplots(1,1,figsize=(10,6))\n",
    "sns.boxplot(data=RI_prob_df_save,x='BASIN',y='30/24',hue='RI Type')#,s=10,jitter=True,ax=ax1)\n",
    "ax1.set_ylim([0,125])\n",
    "ax1.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ff00a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname_save = 'DATA/SHIPS_RII_rapid_intense_probs_{yr}.csv'.format(yr=yr_sel)\n",
    "RI_prob_df_save.to_csv(fname_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbeae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SHIPS",
   "language": "python",
   "name": "ships"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
