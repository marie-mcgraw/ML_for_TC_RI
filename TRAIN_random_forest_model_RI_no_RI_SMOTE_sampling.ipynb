{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8cee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "NUM_THREADS = \"1\"\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = NUM_THREADS\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = NUM_THREADS\n",
    "os.environ[\"MKL_NUM_THREADS\"] = NUM_THREADS\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = NUM_THREADS\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = NUM_THREADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc95c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# from utils.SHIPS_preprocess import calc_d24_VMAX, fore_hr_averaging, load_processed_SHIPS\n",
    "# from utils import SHIPS_ML_model_funcs\n",
    "# from utils.SHIPS_ML_model_funcs import get_train_test_split, SHIPS_train_test_shuffle_CLASS, SHIPS_train_test_split\n",
    "# from utils import SHIPS_plotting\n",
    "from TEST_OLD_UTILS.SHIPS_preprocess import SHIPS_train_test_split, calc_d24_VMAX, fore_hr_averaging, SHIPS_train_test_shuffle_CLASS\n",
    "from TEST_OLD_UTILS.SHIPS_preprocess import load_processed_SHIPS, calculate_class_weights, get_RI_classes\n",
    "from TEST_OLD_UTILS.SHIPS_ML_model_funcs import apply_class_label, calc_CM_stats, get_scores_class_rept, get_roc_auc, get_feature_importances_RF\n",
    "from TEST_OLD_UTILS.SHIPS_ML_model_funcs import get_confusion_matrix_RF, get_scores_best_params_RF, create_gridsearch_RF, get_train_test_split\n",
    "from TEST_OLD_UTILS.SHIPS_ML_model_funcs import calc_AUPD, calculate_PD_curves\n",
    "from TEST_OLD_UTILS.SHIPS_plotting import plot_roc_curve, plot_precision_recall_vs_threshold,add_model_results,make_performance_diagram_background\n",
    "from TEST_OLD_UTILS.SHIPS_plotting import plot_CSI_vs_bias, plot_basic_score_basin, plot_PD_curves\n",
    "#\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,confusion_matrix,accuracy_score,precision_score,recall_score,classification_report\n",
    "from sklearn.metrics import precision_recall_curve, auc, f1_score, fbeta_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.colors\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from utils.SHIPS_ML_model_funcs_imblearn import create_gridsearch_RF_sampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796a4c7",
   "metadata": {},
   "source": [
    "##### Ignore Annoying Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c27030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "#\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(action=\"ignore\",category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ea2e6",
   "metadata": {},
   "source": [
    "### Model Parameters\n",
    "\n",
    "##### SHIPS Dataset Choice\n",
    "* `max_fore`: maximum forecast hours [usually 24 or 48]\n",
    "* `mask_TYPE`: how are we handling cases close to land? [SIMPLE_MASK or no_MASK]\n",
    "* `interp_str`: Did we interpolate over missing data or not? [INTERP: yes, no_INTERP: no]\n",
    "* `yr_start`:  First year of training data [2010 or 2005, generally]\n",
    "* `yr_end_LOAD`:  Last year of full data (to find file)[2021]\n",
    "* `yr_end_TRAIN`: Last year to use in training [2018 is default]\n",
    "* `use_basin`:  Default is to use all basins, but if we just want to use one basin, we can specify that here [ATLANTIC, EAST_PACIFIC, WEST_PACIFIC, and SOUTHERN_HEM are the choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d685543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fore = 24 # maximum forecast hours\n",
    "mask_TYPE = 'SIMPLE_MASK' # how are we handling the land mask?\n",
    "interp_str = 'INTERP' # did we interpolate?\n",
    "yr_start = 2005\n",
    "yr_end_LOAD = 2021\n",
    "yr_end_TRAIN = 2018\n",
    "use_basin = 'ALL'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ecc2ad",
   "metadata": {},
   "source": [
    "#### SHIPS analysis choices\n",
    "* `hrs_max`: maximum forecast hours (usually 24; should be same or less than `max_fore`)\n",
    "* `RI_thresh`: change in wind speed over `hrs_max` needed for RI; default threshold is `30` kt increase in wind speed in `24` hours\n",
    "* `is_RI_only`: flag for future instances of a multi-class classification problem (should always be set to `True` for now)\n",
    "* `n_classes`: related to `is_RI_only`; how many classes are we classifying into (should be `2` for now)\n",
    "* `is_standard`: flag to indicate whether or not we want to do feature scaling with `StandardScaler` (default is `True`)\n",
    "* `DO_AVG`: flag to indicate whether or not we are averaging over our forecast period or treating each 6-hrly forecast as a separate predictor (default is `True`)\n",
    "* `drop_features`: list of features to drop before model training (usually needed for preprocessing but we don't want to train the model on them).  Commonly dropped features include:\n",
    "    * `TYPE`: storm type; should be 1 everywhere (tropical cyclones only)\n",
    "    * `VMAX`: maximum surface winds; we define our classes based entirely on `VMAX` so we don't want it in our features\n",
    "    * `DELV`: we only use `DELV -12` (change in wind speeds from -12 h to 0 h) and not the change in wind speeds relative to 0 for all hours\n",
    "    * `VMPI`: we calculated `POT` (basically `VMPI` - `VMAX_0`) so we don't need to also include `VMPI`\n",
    "    * `is_TRAIN`: just a flag we use to separate training data from validation in our bootstrapped experiments; not an actual feature to train on \n",
    "* `to_IND`: list of quantities we want to index on for our multi-index (note that these quantities will NOT be considered features)\n",
    "    * `BASIN`: ocean basin\n",
    "    * `CASE`: case number\n",
    "    * `NAME`: name of tropical cyclone\n",
    "    * `DATE_full`: date of case (YYYY-MM-DD-HH:MM:SS).  Time stamp is for `time 0`\n",
    "    * `TIME`: forecast time.  should range from `0` to `max_fore_hrs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4e9bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs_max = 24\n",
    "# Features to drop before ML model\n",
    "drop_features = {'TYPE','VMAX','DELV','VMPI','is_TRAIN'}\n",
    "to_IND = ['BASIN','CASE','NAME','DATE_full','TIME']\n",
    "RI_thresh = 30\n",
    "is_RI_only = True\n",
    "n_classes = 2\n",
    "is_standard = True\n",
    "if is_standard == True:\n",
    "    stand_str = 'STANDARDIZED'\n",
    "else:\n",
    "    stand_str = 'noSTANDARDIZED'\n",
    "DO_AVG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82b644",
   "metadata": {},
   "source": [
    "#### ML Model Hyperparameters.  This will change based on the type of model\n",
    "* <code>score</code>:  For RF models, this measures quality of a split (called `criterion` in `sklearn`).  Options are `gini` (measures Gini impurity), `log_loss`, and `entropy` (both measure Shannon information gain). \n",
    "* <code>max_features</code>: Maximum number of features per tree.  For classification problems should be approximately $\\sqrt{N_{features}}$.  For us, $\\sqrt{N_{features}} \\approx 4.2$, so we use `[4,5]` as options for `max_features`\n",
    "* `n_estimators`: number of decision trees. We try `[250, 500]`. \n",
    "* `min_samples_leaf`: min. number of samples needed to create a leaf node. We try `[2,4]`\n",
    "* `max_depth`: maximum depth of each decision tree.  We try `[5,6,8]`. Note that generally RF performance improves as `max_depth` increases, but we run the risk of overfitting + model training takes longer, so this is our compromise.  \n",
    "* <code>k_folds</code>: number of folds used in our cross-validation approach.  We will use a <code>Stratified K-Means cross-validation</code> since we have imbalanced classes. Default is `10`\n",
    "* `n_repeats`: number of times we repeat k-folds cross-validation process. Default is `3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3defcfec",
   "metadata": {},
   "source": [
    "##### Class weighting\n",
    "This part is tricky but important.  Since we are really interested in rapid intensification, which is by definition, rare, we will inherently be creating imbalanced classes for our data.  We can address this in many ways.  Broadly, we can either use <b>class weights</b> (which apply different weights to each data point based on which class it is in), or we can use under/over sampling.  <b>Undersampling</b> means we will sample the minority class at a rate that is commeasurate with the majority class--we lose information, but are less likely to overfit to our minority class.  <b>Oversampling</b> means we will draw additional samples from our minority class to match the size of our majority class.  \n",
    "\n",
    "We'll try a few different ways of applying class weights, and we'll try undersampling.  Since our minority classes can be quite small, we will avoid oversampling (for now, at least)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0800eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = ['gini']\n",
    "k_folds = 10\n",
    "n_repeats = 3\n",
    "\n",
    "# Weights\n",
    "use_custom_wts = False\n",
    "no_wts = True\n",
    "# We want to predict intensity class for each case\n",
    "to_predict = 'I_class'\n",
    "# Model hyperparameters\n",
    "max_features = [4,5]\n",
    "#max_features = [5]\n",
    "# max_depth = [8]\n",
    "max_depth = [5,6,8,11]\n",
    "min_samples_leaf = [10]\n",
    "# n_estimators = [250]\n",
    "n_estimators = [200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e99431ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_format = 'png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b84edd",
   "metadata": {},
   "source": [
    "##### Load our pre-processed SHIPS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7022b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_SHIPS(yr_start,yr_end,mask_TYPE,max_fore,interp_str,use_basin='ALL'):\n",
    "    SHIPS_predictors = pd.DataFrame()\n",
    "    fpath_load = 'DATA/processed/'\n",
    "    if use_basin == 'ALL':\n",
    "        BASIN = ['ATLANTIC','EAST_PACIFIC','WEST_PACIFIC','SOUTHERN_HEM']\n",
    "    else:\n",
    "        BASIN = [use_basin]\n",
    "    #\n",
    "    for i_name in BASIN:\n",
    "        fname_load = fpath_load+'SHIPS_processed_{BASIN}_set_yrs_{yr_start}-{yr_end}_max_fore_hr_{max_fore}_{interp_str}_'\\\n",
    "        'land_mask_{mask_TYPE}.csv'.format(BASIN=i_name,yr_start=yr_start,yr_end=yr_end,\n",
    "                                          max_fore=max_fore,interp_str=interp_str,mask_TYPE=mask_TYPE)\n",
    "        iload = pd.read_csv(fname_load)\n",
    "        # Change RSST / RHCN to NSST / NOHC just to keep naming consistent\n",
    "        if (i_name != 'ATLANTIC') | (i_name != 'EAST_PACIFIC'):\n",
    "            iload = iload.rename(columns={'RSST':'NSST','RHCN':'NOHC'})\n",
    "        #\n",
    "        iload['BASIN'] = i_name\n",
    "        SHIPS_predictors = SHIPS_predictors.append(iload)\n",
    "        #\n",
    "    SHIPS_predictors = SHIPS_predictors.drop(columns={'level_0','index'})\n",
    "    return SHIPS_predictors,BASIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4313ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIPS_predictors,BASIN = load_processed_SHIPS(yr_start,yr_end_LOAD,mask_TYPE,max_fore,interp_str,use_basin)\n",
    "#\n",
    "FULL_yrs = np.arange(yr_start,yr_end_TRAIN+1,1)\n",
    "SHIPS_predictors = SHIPS_predictors[pd.to_datetime(SHIPS_predictors['DATE_full']).dt.year.isin(FULL_yrs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65ffab",
   "metadata": {},
   "source": [
    "##### Calculate class weights, if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b671627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "if use_custom_wts:\n",
    "    class_wts = calculate_class_weights(SHIPS_predictors,n_classes,RI_thresh,0)\n",
    "    weights_use = class_wts.xs(use_basin)\n",
    "    wts_sel = weights_use['WEIGHT'].to_dict()\n",
    "    wts_str = 'custom_wts'\n",
    "elif no_wts == True:\n",
    "    wts_str = None\n",
    "else:\n",
    "    wts_sel = 0\n",
    "    wts_str = 'default_wts'\n",
    "print(wts_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa97efe",
   "metadata": {},
   "source": [
    "##### Bootstrapped model training\n",
    "First, initialize some dataframes for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb4dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_ALL = pd.DataFrame()\n",
    "roc_vals_ALL = pd.DataFrame()\n",
    "p_vs_r_ALL = pd.DataFrame()\n",
    "fi_pred_ALL = pd.DataFrame()\n",
    "fi_pred_train_ALL = pd.DataFrame()\n",
    "cm_ALL = pd.DataFrame()\n",
    "report_ALL = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd590b7",
   "metadata": {},
   "source": [
    "Next, outline our bootstrapping experiments\n",
    "###### Bootstrapping parameters:\n",
    "\n",
    "* `N_samples`: number of experiments\n",
    "* `ncats`: number of categories for classification (default is 2)\n",
    "* `scoring`: scoring function for ML model (we typically used `f1_weighted` as it's better for imbalanced classes)\n",
    "* `n_valid`: number of years to use for validation\n",
    "\n",
    "###### Overview\n",
    "1. Of full training period (2005-2018), we randomly select `n_valid` years to use for validation.  We use a modified leave-one-year-out approach (where instead we leave `n_valid` years out. This step is handled by the `get_train_test_split` function.  Thus we divide our SHIPS predictors as well as our target variable into training and validation samples based on year. \n",
    "2. We set up a hyperparameter sweep using `sklearn`'s `gridsearchCV` (contained in `create_gridsearch_RF` function).  For random forest, we explore 4 hyperparameters, identified earlier in this notebook.\n",
    "3. After identifying best hyperparameters, we train (`model.fit()`).  We train once on cases from all ocean basins.\n",
    "4. Once training is complete, we try to predict class of our validation years.  We predict each ocean basin separately, as well as predict all ocean basins combined. We use `get_scores_best_params_RF` to get the hyperparameters for our best model, `get_confusion_matrix_RF` to get the confusion matrix and contingency table stats for our model, `get_feature_importances_RF` to get the feature importances, and `get_roc_AUC` to get the receiver operator curve (ROC) and area under the curve (AUC). \n",
    "5. We save all of the output and repeat the process, selecting new validation years and fully re-training every time until we have done `N_samples` experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a688d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_steps = [(sampler_str[i],sampler[i]) for i in np.arange(0,len(sampler))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9218225",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sample  0\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n",
      "running  ALL\n",
      "running sample  1\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  ALL\n",
      "running sample  2\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  ALL\n",
      "running sample  3\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n",
      "running  ALL\n",
      "running sample  4\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  ALL\n",
      "running sample  5\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n",
      "running  ALL\n",
      "running sample  6\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n",
      "running  ALL\n",
      "running sample  7\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n",
      "running  ALL\n",
      "running sample  8\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  ALL\n",
      "running sample  9\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  ALL\n",
      "running sample  10\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n",
      "running  ALL\n",
      "running sample  11\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n",
      "running  ALL\n",
      "running sample  12\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  SOUTHERN_HEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  ALL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sample  13\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n",
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n",
      "running  SOUTHERN_HEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  ALL\n",
      "running sample  14\n",
      "averaging hours together\n",
      "fitting model\n",
      "calculating scores\n",
      "running  ATLANTIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  EAST_PACIFIC\n",
      "running  WEST_PACIFIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  SOUTHERN_HEM\n",
      "running  ALL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/mmcgraw/ML_for_TC_RI/TEST_OLD_UTILS/SHIPS_ML_model_funcs.py:368: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = (2*p*r)/(p+r)\n"
     ]
    }
   ],
   "source": [
    "# Experiment parameters\n",
    "N_samples = 15\n",
    "ncats = 2\n",
    "scoring = 'f1_weighted'\n",
    "cut = 'equal'\n",
    "sampler = SMOTE(sampling_strategy = 0.5)\n",
    "sampler_str = 'over'\n",
    "sampler2 = RandomUnderSampler(sampling_strategy = 0.5)\n",
    "sampler_str2 = 'under'\n",
    "sampler_str_ALL = [sampler_str,sampler_str2]\n",
    "sampler_ALL = [sampler,sampler2]\n",
    "# FULL_yrs = np.arange(yr_start,yr_end_TRAIN,1)\n",
    "n_valid = 3 # number of years to leave out for validation\n",
    "\n",
    "# Loop through bootstrapping examples\n",
    "for i in np.arange(0,N_samples):\n",
    "    print('running sample ',i)\n",
    "    # Split data into training/validation\n",
    "    test_years = np.random.choice(FULL_yrs,n_valid,replace=False) # years we will use for validation\n",
    "    X_train, X_test, y_train, y_test, feature_names, diff_train, diff_test = get_train_test_split(test_years,SHIPS_predictors,to_predict,\n",
    "                                                                    is_RI_only,to_IND,drop_features,DO_AVG,RI_thresh,hrs_max)\n",
    "    # Set up hyperparameter sweep\n",
    "    LR_model = create_gridsearch_RF_sampler(is_standard,score,max_depth,n_estimators,max_features,min_samples_leaf,\n",
    "                                k_folds,n_repeats,scoring,sampler_ALL,sampler_str_ALL)\n",
    "    print('fitting model')\n",
    "    # Fit model using training data. We train on cases from all 4 basins\n",
    "    LR_model.fit(X_train,y_train['I_class'])\n",
    "    # \n",
    "    BASIN_all = ['ATLANTIC', 'EAST_PACIFIC', 'WEST_PACIFIC', 'SOUTHERN_HEM','ALL']\n",
    "    print('calculating scores')\n",
    "    # Perform validation.  We'll analyze each basin separately as well as combined scores for all basins together\n",
    "    for basin in BASIN_all:\n",
    "        # basin = 'ATLANTIC'\n",
    "        print('running ',basin)\n",
    "        # Get best hyperparams\n",
    "        report, y_true, y_pred = get_scores_best_params_RF(LR_model,X_test,y_test,basin)\n",
    "        report['Years Out'] = str(test_years)\n",
    "        report['Model'] = 'Random Forest'\n",
    "        report['Fold'] = i\n",
    "        label_names = ['not RI','RI']\n",
    "        # Get confusion matrix\n",
    "        cm_stats = get_confusion_matrix_RF(LR_model,y_true,y_pred,basin,label_names,ncats)\n",
    "        cm_stats['Years Out'] = str(test_years)\n",
    "        cm_stats['Model'] = 'Random Forest'\n",
    "        cm_stats['Fold'] = i\n",
    "        # Get feature importances\n",
    "        fi_pred = get_feature_importances_RF(LR_model,X_train,y_train,basin,scoring)\n",
    "        fi_pred['Years Out'] = str(test_years)\n",
    "        fi_pred['Model'] = 'Random Forest'\n",
    "        fi_pred['Fold'] = i\n",
    "        # Feature importances for training data\n",
    "        fi_pred_train = get_feature_importances_RF(LR_model,X_train,y_train,basin,scoring)\n",
    "        fi_pred_train['Years Out'] = str(test_years)\n",
    "        fi_pred_train['Fold'] = i\n",
    "        fi_pred_train['Model'] = 'Random Forest'\n",
    "        # Get ROC curve and AUC score\n",
    "        ypred_prob, p_vs_r, roc_vals = get_roc_auc(X_test,basin,LR_model,y_test,1,'RI',scoring,'equal')\n",
    "        # Save info like experiment #, years used for validation, etc\n",
    "        p_vs_r['Fold'] = i\n",
    "        p_vs_r['Years Out'] = str(test_years)\n",
    "        p_vs_r['Model'] = 'Random Forest'\n",
    "        roc_vals['Fold'] = i\n",
    "        roc_vals['Years Out'] = str(test_years)\n",
    "        roc_vals['Model'] = 'Random Forest'\n",
    "        # Get actual predictions for target variable Y\n",
    "        if basin != 'ALL':\n",
    "            y_pred_all = y_test.xs(basin).copy()\n",
    "        else:\n",
    "            y_pred_all = y_test.copy()\n",
    "        # Save predicted values of Y\n",
    "        y_pred_all['Y pred'] = y_pred\n",
    "        y_pred_all['Predicted Basin'] = basin\n",
    "        y_pred_all['Model'] = 'Random Forest'\n",
    "        # Get probabilities for 0 (not-RI) and 1 (RI)\n",
    "        y_pred_all['Y pred probab (class: 0)'] = ypred_prob[:,0]\n",
    "        y_pred_all['Y pred probab (class: 1)'] = ypred_prob[:,1]\n",
    "        # Store everything before going on to next experiment\n",
    "        predicted_y_ALL = predicted_y_ALL.append(y_pred_all)\n",
    "        roc_vals_ALL = roc_vals_ALL.append(roc_vals)\n",
    "        p_vs_r_ALL = p_vs_r_ALL.append(p_vs_r)\n",
    "        fi_pred_ALL = fi_pred_ALL.append(fi_pred)\n",
    "        fi_pred_train_ALL = fi_pred_train_ALL.append(fi_pred_train)\n",
    "        cm_ALL = cm_ALL.append(cm_stats)\n",
    "        report_ALL = report_ALL.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c14a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SR</th>\n",
       "      <th>POD</th>\n",
       "      <th>N_predicted</th>\n",
       "      <th>Threat</th>\n",
       "      <th>N_actual</th>\n",
       "      <th>Correct Negs</th>\n",
       "      <th>Category</th>\n",
       "      <th>PFOD</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Misses</th>\n",
       "      <th>False Alarms</th>\n",
       "      <th>FAR</th>\n",
       "      <th>BIAS</th>\n",
       "      <th>Max Depth</th>\n",
       "      <th>Max Features</th>\n",
       "      <th>N Estimators</th>\n",
       "      <th>Min Samples Leaf</th>\n",
       "      <th>Fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BASIN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ATLANTIC</th>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.316618</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.244406</td>\n",
       "      <td>44.0</td>\n",
       "      <td>168.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066780</td>\n",
       "      <td>14.5</td>\n",
       "      <td>27.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.689988</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAST_PACIFIC</th>\n",
       "      <td>0.448986</td>\n",
       "      <td>0.635029</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.346726</td>\n",
       "      <td>57.5</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.208212</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.551014</td>\n",
       "      <td>1.506876</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEST_PACIFIC</th>\n",
       "      <td>0.574277</td>\n",
       "      <td>0.745904</td>\n",
       "      <td>149.5</td>\n",
       "      <td>0.481412</td>\n",
       "      <td>116.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.242879</td>\n",
       "      <td>96.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.425723</td>\n",
       "      <td>1.292282</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTHERN_HEM</th>\n",
       "      <td>0.456449</td>\n",
       "      <td>0.576887</td>\n",
       "      <td>99.5</td>\n",
       "      <td>0.343033</td>\n",
       "      <td>79.5</td>\n",
       "      <td>248.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>45.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.543551</td>\n",
       "      <td>1.380659</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>0.523209</td>\n",
       "      <td>0.646115</td>\n",
       "      <td>365.0</td>\n",
       "      <td>0.400824</td>\n",
       "      <td>284.5</td>\n",
       "      <td>776.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199891</td>\n",
       "      <td>198.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.476791</td>\n",
       "      <td>1.278077</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    SR       POD  N_predicted    Threat  N_actual  \\\n",
       "BASIN                                                               \n",
       "ATLANTIC      0.522727  0.316618         27.5  0.244406      44.0   \n",
       "EAST_PACIFIC  0.448986  0.635029         82.5  0.346726      57.5   \n",
       "WEST_PACIFIC  0.574277  0.745904        149.5  0.481412     116.0   \n",
       "SOUTHERN_HEM  0.456449  0.576887         99.5  0.343033      79.5   \n",
       "ALL           0.523209  0.646115        365.0  0.400824     284.5   \n",
       "\n",
       "              Correct Negs  Category      PFOD   Hits  Misses  False Alarms  \\\n",
       "BASIN                                                                         \n",
       "ATLANTIC             168.5       1.0  0.066780   14.5    27.5          14.5   \n",
       "EAST_PACIFIC         169.0       1.0  0.208212   38.0    18.0          47.5   \n",
       "WEST_PACIFIC         195.0       1.0  0.242879   96.0    24.0          55.0   \n",
       "SOUTHERN_HEM         248.0       1.0  0.207921   45.5    27.0          54.0   \n",
       "ALL                  776.5       1.0  0.199891  198.0   102.0         175.0   \n",
       "\n",
       "                   FAR      BIAS  Max Depth  Max Features  N Estimators  \\\n",
       "BASIN                                                                     \n",
       "ATLANTIC      0.477273  0.689988        8.0           5.0         200.0   \n",
       "EAST_PACIFIC  0.551014  1.506876        8.0           5.0         200.0   \n",
       "WEST_PACIFIC  0.425723  1.292282        8.0           5.0         200.0   \n",
       "SOUTHERN_HEM  0.543551  1.380659        8.0           5.0         200.0   \n",
       "ALL           0.476791  1.278077        8.0           5.0         200.0   \n",
       "\n",
       "              Min Samples Leaf  Fold  \n",
       "BASIN                                 \n",
       "ATLANTIC                  10.0   2.0  \n",
       "EAST_PACIFIC              10.0   2.0  \n",
       "WEST_PACIFIC              10.0   2.0  \n",
       "SOUTHERN_HEM              10.0   2.0  \n",
       "ALL                       10.0   2.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_ALL.set_index(['Category Names','BASIN']).xs(('RI')).median(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(X_test.reset_index()['DATE_full']).dt.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc959c0",
   "metadata": {},
   "source": [
    "##### Create output directory and set up file extensions for saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For naming purposes\n",
    "predicted_y_ALL['BASIN'] = predicted_y_ALL['Predicted Basin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'DATA/ML_model_results/TRAINING/'\n",
    "model_type = 'RF'\n",
    "save_dir = save_dir+model_type+'/'\n",
    "save_extension = 'OLD_FUNCS_TRAIN_OVER_UNDERSAMPLE_{score}_SHIPS_SIMPLE_RI_vs_no_RI_{yr_start}-{yr_end}_{mask_TYPE}_{stand_str}_RI_thresh_{RI_thresh}'\\\n",
    "'weights_{wts_str}_{N}_samples_{scoring}.csv'.format(score=score[0],yr_start=yr_start,yr_end=yr_end_TRAIN,mask_TYPE=mask_TYPE,\n",
    "                           stand_str=stand_str,RI_thresh=RI_thresh,wts_str=wts_str,N=N_samples,scoring=scoring)\n",
    "\n",
    "save_ext_figs = 'OLD_FUNCS_TRAIN_OVER_UNDERSAMPLE_{score}_SHIPS_SIMPLE_RI_vs_no_RI_{yr_start}-{yr_end}_{mask_TYPE}_{stand_str}_RI_thresh_{RI_thresh}'\\\n",
    "'weights_{wts_str}_{N}_samples_{scoring}.{fig_format}'.format(score=score[0],yr_start=yr_start,yr_end=yr_end_TRAIN,mask_TYPE=mask_TYPE,\n",
    "                           stand_str=stand_str,RI_thresh=RI_thresh,wts_str=wts_str,N=N_samples,scoring=scoring,\n",
    "                                                             fig_format=fig_format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3d463e",
   "metadata": {},
   "source": [
    "##### Create subdirectories if they don't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfff555",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "# figs directory\n",
    "if not os.path.exists(save_dir+'/figs/'):\n",
    "    os.makedirs(save_dir+'/figs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ff1a99",
   "metadata": {},
   "source": [
    "##### Actually save everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d021d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_ALL.to_csv(save_dir+'PREDICTED_Y_vals'+save_extension)\n",
    "print('saved y vals')\n",
    "roc_vals_ALL.to_csv(save_dir+'ROC_AUC_vals'+save_extension)\n",
    "print('saved ROC vals')\n",
    "p_vs_r_ALL.to_csv(save_dir+'Prec_vs_recall'+save_extension)\n",
    "print('saved precision / recall values')\n",
    "fi_pred_ALL.to_csv(save_dir+'Feat_Imp_validation'+save_extension)\n",
    "print('saved feat importances')\n",
    "fi_pred_train_ALL.to_csv(save_dir+'Feat_Imp_TRAIN'+save_extension)\n",
    "print('saved feat importances (training)')\n",
    "cm_ALL.to_csv(save_dir+'Conf_Matrix'+save_extension)\n",
    "print('saved confusion matrix')\n",
    "report_ALL.to_csv(save_dir+'Class_Report'+save_extension)\n",
    "print('saved classification report')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafc307a",
   "metadata": {},
   "source": [
    "#### Make some basic plots for this RF model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6984aac",
   "metadata": {},
   "source": [
    "###### Precision vs Recall plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4dcb7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_vs_r_ALL_plt = p_vs_r_ALL.reset_index()#.iloc[::2]\n",
    "#basin_sel = 'ALL'\n",
    "for basin_sel in BASIN_all:\n",
    "    foo = p_vs_r_ALL_plt.set_index(['BASIN']).loc[basin_sel].drop(columns={'index'})\n",
    "    foo2 = foo.copy()\n",
    "    foo2['Thresholds Round'] = foo2['Thresholds'].round(2)\n",
    "    means_plt = foo2.groupby(['Thresholds Round']).mean().reset_index()\n",
    "    fig1,ax1 = plt.subplots(1,1,figsize=(10,6))\n",
    "    sns.lineplot(data=foo2.reset_index(),x='Thresholds',y='Recall',hue='Fold',ax=ax1,alpha=0.25,legend=None)\n",
    "    sns.lineplot(data=foo2.reset_index(),x='Thresholds',y='Precision',hue='Fold',ax=ax1,alpha=0.25,legend=None)\n",
    "    sns.lineplot(data=foo2.reset_index(),x='Thresholds',y='F1',hue='Fold',ax=ax1,alpha=0.25,legend=None)\n",
    "    thresh_min = foo2.reset_index()['Cutoff Threshold'].min()\n",
    "    thresh_max = foo2.reset_index()['Cutoff Threshold'].max()\n",
    "    ax1.axvspan(thresh_min,thresh_max,alpha=0.35,color='xkcd:gray',label='Cutoff Threshold')\n",
    "    sns.lineplot(data=means_plt,x='Thresholds Round',y='Recall',ax=ax1,linewidth=6,color='xkcd:crimson',label='Recall')\n",
    "    sns.lineplot(data=means_plt,x='Thresholds Round',y='Precision',ax=ax1,linewidth=6,color='xkcd:sky blue',label='Precision')\n",
    "    sns.lineplot(data=means_plt,x='Thresholds Round',y='F1',ax=ax1,linewidth=6,color='xkcd:goldenrod',label='F1')\n",
    "    ax1.set_xlabel('Thresholds',fontsize=19)\n",
    "    ax1.set_ylabel('Score',fontsize=19)\n",
    "    ax1.legend(fontsize=13)\n",
    "    ax1.grid()\n",
    "    ax1.set_title('Precision vs Recall, Identifying RI, {basin_sel} Basins, RF model'.format(basin_sel=basin_sel),fontsize=21)\n",
    "    fig1.savefig(save_dir+'figs/P_vs_R_{basin_sel}'.format(basin_sel=basin_sel)+save_ext_figs,format=fig_format,\n",
    "                 dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f293f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3,ax3 = plt.subplots(1,1,figsize=(10,6))\n",
    "sns.boxplot(data=roc_vals_ALL,x='BASIN',y='AUC ROC Score',ax=ax3)\n",
    "ax3.set_ylim([0,1])\n",
    "ax3.set_xticklabels(roc_vals_ALL['BASIN'].unique(),fontsize=16,rotation=60)\n",
    "ax3.set_ylabel('AUC Score',fontsize=18)\n",
    "ax3.set_title('AUC Scores, {solver}'.format(solver='RF'),fontsize=21)\n",
    "fig3.savefig(save_dir+'figs/AUC_scores_all_basins_RF'+save_ext_figs,\n",
    "            format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f823beb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report_plot = report_ALL.reset_index().rename(columns={'index':'Scores','0.0':'not RI','1.0':'RI'})\n",
    "report_plt_all = report_plot.set_index(['Scores','BASIN','Fold'])\n",
    "score_sel_ALL = ['recall','precision','f1-score','support']\n",
    "for score_sel in score_sel_ALL:\n",
    "    report_plt_mean = report_plt_all.xs((score_sel)).reset_index()\n",
    "    fig4,ax4 = plt.subplots(1,1,figsize=(10,6))\n",
    "    sns.boxplot(data=report_plt_mean,x='BASIN',y='RI',ax=ax4)\n",
    "    if score_sel == 'support':\n",
    "        ax4.set_ylim([0,400])\n",
    "    else:\n",
    "        ax4.set_ylim([0,1])\n",
    "    ax4.set_ylabel('Classifying RI',fontsize=16)\n",
    "    ax4.set_xlabel(None)\n",
    "    ax4.set_xticklabels(report_plt_mean['BASIN'].unique(),fontsize=15,rotation=40)\n",
    "    ax4.grid()\n",
    "    ax4.set_title(' {score_sel}, Classifying RI Cases, RF'.format(score_sel=score_sel),fontsize=20)\n",
    "    fig4.savefig(save_dir+'figs/{score_sel}_all_samples_RI_cases_RF'+save_ext_figs,\n",
    "                format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e39d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_plt2 = report_plt_all.loc[['precision','recall','f1-score']].mean(level=(0,1)).reset_index()\n",
    "fig5,(ax5a,ax5b) = plt.subplots(2,1,figsize=(10,8))\n",
    "sns.scatterplot(data=report_plt2,x='BASIN',y='not RI',hue='Scores',palette='twilight',s=130,ax=ax5a,alpha=0.7,legend=False)\n",
    "sns.lineplot(data=report_plt2,x='BASIN',y='not RI',hue='Scores',palette='twilight',linewidth=2,ax=ax5a,alpha=0.7)\n",
    "\n",
    "sns.scatterplot(data=report_plt2,x='BASIN',y='RI',hue='Scores',palette='magma',s=130,ax=ax5b,alpha=0.7,legend=False)\n",
    "sns.lineplot(data=report_plt2,x='BASIN',y='RI',hue='Scores',palette='magma',linewidth=2,ax=ax5b,alpha=0.7)\n",
    "\n",
    "ax5a.set_ylim([0,1])\n",
    "ax5b.set_ylim([0,1])\n",
    "ax5a.set_ylabel('not RI',fontsize=18)\n",
    "ax5b.set_ylabel('RI',fontsize=18)\n",
    "ax5a.set_xticklabels(report_plt2['BASIN'].unique(),fontsize=14,rotation=30)\n",
    "ax5a.set_xlabel(None)\n",
    "ax5b.set_xticklabels(report_plt2['BASIN'].unique(),fontsize=14,rotation=30)\n",
    "ax5b.set_xlabel(None)\n",
    "ax5a.grid()\n",
    "ax5b.grid()\n",
    "ax5a.legend(fontsize=13)\n",
    "ax5b.legend(fontsize=13)\n",
    "fig5.suptitle('Precision, Recall, and F1 Scores, Averaged Over Bootstrapped Samples, RF',fontsize=20)\n",
    "fig5.tight_layout()\n",
    "fig5.savefig(save_dir+'figs/Scores_averaged_RI_non_RI'+save_ext_figs,\n",
    "            format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099785b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for basin_sel in BASIN_all:\n",
    "    fig2,ax2 = plt.subplots(1,1,figsize=(10,7))\n",
    "    roc_vals_plt = roc_vals_ALL.set_index(['BASIN']).xs(basin_sel).reset_index()\n",
    "    roc_min = roc_vals_plt['AUC ROC Score'].min()\n",
    "    roc_max = roc_vals_plt['AUC ROC Score'].max()\n",
    "\n",
    "    sns.lineplot(data=roc_vals_plt,x='False Positive Rate',y='True Positive Rate',hue='Fold',ax=ax2,legend=False,\n",
    "                alpha=0.3)\n",
    "    ax2.plot([0,1],[0,1],color='k',linewidth=2)\n",
    "    ax2.axhspan(roc_min,roc_max,color='xkcd:gray',alpha=0.25,label='AUC Score')\n",
    "    ax2.set_xlabel('False Positive Rate',fontsize=18)\n",
    "    ax2.set_ylabel('True Positive Rate',fontsize=18)\n",
    "    roc_vals_mean = roc_vals_plt.groupby(roc_vals_plt['False Positive Rate'].round(2))[['True Positive Rate',\n",
    "                                    'AUC Thresholds']].mean().reset_index()\n",
    "    roc_vals_mean.plot(x='False Positive Rate',y='True Positive Rate',ax=ax2,color='xkcd:tangerine',linewidth=5,\n",
    "                      label='ROC curve')\n",
    "    ax2.legend(fontsize=13)\n",
    "    ax2.grid()\n",
    "    ax2.set_title('Identifying RI versus non-RI, {basin_sel} Basins, {solver} model'.format(basin_sel=basin_sel,\n",
    "                                                                                           solver='RF'),fontsize=21)\n",
    "    f2_save = save_dir+'figs/ROC_curve_{basin_sel}'.format(basin_sel=basin_sel)\n",
    "    fig2.savefig(f2_save+save_ext_figs,format=fig_format,\n",
    "                 dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08960469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(data=cm_ALL,x='Category',y='Misses')\n",
    "cm_ALL['BIAS'] = (cm_ALL['Hits']+cm_ALL['False Alarms'])/(cm_ALL['Hits'] + cm_ALL['Misses'])\n",
    "\n",
    "fig6,((ax6a,ax6b),(ax6c,ax6d)) = plt.subplots(2,2,figsize=(14,10))\n",
    "sns.boxplot(data=cm_ALL,x='BASIN',y='Misses',hue='Category Names',palette='twilight',ax=ax6a)\n",
    "ax6a.set_ylabel('Misses',fontsize=15)\n",
    "ax6a.legend(fontsize=12)\n",
    "ax6a.set_xticklabels(cm_ALL['BASIN'].unique(),fontsize=14,rotation=30)\n",
    "ax6a.set_title('Misses',fontsize=19)\n",
    "ax6a.set_xlabel(None)\n",
    "#\n",
    "sns.boxplot(data=cm_ALL,x='BASIN',y='Hits',hue='Category Names',palette='twilight',ax=ax6b)\n",
    "ax6b.set_ylabel('Hits',fontsize=15)\n",
    "ax6b.legend(fontsize=12)\n",
    "ax6b.set_xticklabels(cm_ALL['BASIN'].unique(),fontsize=14,rotation=30)\n",
    "ax6b.set_title('Hits',fontsize=19)\n",
    "ax6b.set_xlabel(None)\n",
    "#\n",
    "sns.boxplot(data=cm_ALL,x='BASIN',y='POD',hue='Category Names',palette='twilight',ax=ax6c)\n",
    "ax6c.set_ylabel('POD',fontsize=15)\n",
    "ax6c.legend(fontsize=12)\n",
    "ax6c.set_xticklabels(cm_ALL['BASIN'].unique(),fontsize=14,rotation=30)\n",
    "ax6c.set_title('Probability of Detection',fontsize=19)\n",
    "ax6c.set_xlabel(None)\n",
    "#\n",
    "#\n",
    "sns.boxplot(data=cm_ALL,x='BASIN',y='Threat',hue='Category Names',palette='twilight',ax=ax6d)\n",
    "ax6d.set_ylabel('Threat Score',fontsize=15)\n",
    "ax6d.legend(fontsize=12)\n",
    "ax6d.set_xticklabels(cm_ALL['BASIN'].unique(),fontsize=14,rotation=30)\n",
    "ax6d.set_title('Threat Score',fontsize=19)\n",
    "ax6d.set_xlabel(None)\n",
    "#\n",
    "\n",
    "fig6.suptitle('{solver} Model'.format(solver='RF'),fontsize=21)\n",
    "fig6.tight_layout()\n",
    "fig6.savefig(save_dir+'figs/CM_results_RI_not_RI_RF'+save_ext_figs,\n",
    "            format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7,ax7 = plt.subplots(1,1,figsize=(12,8))\n",
    "fi_plt = fi_pred_ALL.reset_index().sort_values(['BASIN','mean importance'],ascending=False)\n",
    "fi_plt['mean mean'] = fi_plt.groupby(['BASIN','index'])['mean importance'].transform('mean')\n",
    "fi_plt['max mean'] = fi_plt.groupby(['BASIN','index'])['mean importance'].transform('max')\n",
    "fi_plt_plt = fi_plt.sort_values(['BASIN','mean mean','max mean'],ascending=[True,False,False])\n",
    "sns.barplot(data=fi_plt_plt,x='index',y='mean importance',hue='BASIN',\n",
    "            palette='twilight',ax=ax7)\n",
    "ax7.set_xticklabels(fi_plt_plt['index'].unique(),fontsize=14,rotation=50)\n",
    "ax7.set_ylabel('Mean Importance',fontsize=17)\n",
    "ax7.set_xlabel(None)\n",
    "ax7.grid()\n",
    "ax7.tick_params(axis='y',labelsize=14)\n",
    "ax7.legend(fontsize=13)\n",
    "ax7.set_title('Feature Importances, TRAINING DATA, not-RI vs RI, {solver}'.format(solver='RF'),fontsize=21)\n",
    "fig7.tight_layout()\n",
    "fig7.savefig(save_dir+'figs/Feat_Imp_RI_not_RI'+save_ext_figs,\n",
    "            format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828615b8",
   "metadata": {},
   "source": [
    "##### Each basin separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84736e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for basin_sel in BASIN_all:\n",
    "#basin_sel = 'ATLANTIC'\n",
    "    i_plt = fi_pred_ALL.reset_index().set_index(['BASIN']).xs(basin_sel).sort_values(['mean importance'],ascending=False)\n",
    "    i_plt['mean mean'] = i_plt.groupby(['index'])['mean importance'].transform('mean')\n",
    "    i_plt['max mean'] = i_plt.groupby(['index'])['mean importance'].transform('max')\n",
    "    i_plt_plt = i_plt.sort_values(['mean mean','max mean'],ascending=[False,False])\n",
    "    fig7,ax7 = plt.subplots(1,1,figsize=(15,10))\n",
    "\n",
    "    sns.barplot(data=i_plt_plt,x='index',y='mean importance',\n",
    "                palette='twilight',ax=ax7)\n",
    "    ax7.set_xticklabels(i_plt_plt['index'].unique(),fontsize=14,rotation=50)\n",
    "    ax7.set_ylabel('Mean Importance',fontsize=17)\n",
    "    ax7.tick_params(axis='y',labelsize=14)\n",
    "    ax7.set_xlabel(None)\n",
    "    ax7.grid()\n",
    "    #ax7.legend(fontsize=13)\n",
    "    ax7.set_title('Feature Importances, not-RI vs RI, {solver}, {basin}'.format(solver='RF',basin=basin_sel),fontsize=21)\n",
    "    fig7.tight_layout()\n",
    "    fig7.savefig(save_dir+'figs/Feat_Imp_RI_not_RI_{basin_sel}'.format(basin_sel=basin_sel)+save_ext_figs,\n",
    "                format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63b705",
   "metadata": {},
   "source": [
    "###### FI Based on training data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dae57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7,ax7 = plt.subplots(1,1,figsize=(15,10))\n",
    "fi_plt = fi_pred_train_ALL.reset_index().sort_values(['BASIN','mean importance'],ascending=False)\n",
    "fi_plt['mean mean'] = fi_plt.groupby(['BASIN','index'])['mean importance'].transform('mean')\n",
    "fi_plt['max mean'] = fi_plt.groupby(['BASIN','index'])['mean importance'].transform('max')\n",
    "fi_plt_plt = fi_plt.sort_values(['BASIN','mean mean','max mean'],ascending=[True,False,False])\n",
    "sns.barplot(data=fi_plt_plt,x='index',y='mean importance',hue='BASIN',\n",
    "            palette='twilight',ax=ax7)\n",
    "ax7.set_xticklabels(fi_plt_plt['index'].unique(),fontsize=14,rotation=50)\n",
    "ax7.set_ylabel('Mean Importance',fontsize=17)\n",
    "ax7.set_xlabel(None)\n",
    "ax7.grid()\n",
    "ax7.tick_params(axis='y',labelsize=14)\n",
    "ax7.legend(fontsize=13)\n",
    "ax7.set_title('Feature Importances, TRAINING DATA, not-RI vs RI, {solver}'.format(solver='RF'),fontsize=21)\n",
    "fig7.tight_layout()\n",
    "fig7.savefig(save_dir+'figs/Feat_Imp_TRAIN_RI_not_RI'+save_ext_figs,\n",
    "            format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc711ff9",
   "metadata": {},
   "source": [
    "##### And each basin separately again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c19cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for basin_sel in BASIN_all:\n",
    "#basin_sel = 'ATLANTIC'\n",
    "    i_plt = fi_pred_train_ALL.reset_index().set_index(['BASIN']).xs(basin_sel).sort_values(['mean importance'],ascending=False)\n",
    "    i_plt['mean mean'] = i_plt.groupby(['index'])['mean importance'].transform('mean')\n",
    "    i_plt['max mean'] = i_plt.groupby(['index'])['mean importance'].transform('max')\n",
    "    i_plt_plt = i_plt.sort_values(['mean mean','max mean'],ascending=[False,False])\n",
    "    fig7,ax7 = plt.subplots(1,1,figsize=(15,10))\n",
    "\n",
    "    sns.barplot(data=i_plt_plt,x='index',y='mean importance',\n",
    "                palette='twilight',ax=ax7)\n",
    "    ax7.set_xticklabels(i_plt_plt['index'].unique(),fontsize=14,rotation=50)\n",
    "    ax7.set_ylabel('Mean Importance',fontsize=17)\n",
    "    ax7.tick_params(axis='y',labelsize=14)\n",
    "    ax7.set_xlabel(None)\n",
    "    ax7.grid()\n",
    "    #ax7.legend(fontsize=13)\n",
    "    ax7.set_title('Feature Importances, TRAINING DATA, not-RI vs RI, {solver}, {basin}'.format(solver='RF',basin=basin_sel),fontsize=21)\n",
    "    fig7.tight_layout()\n",
    "    fig7.savefig(save_dir+'figs/Feat_Imp_RI_not_RI_TRAINING_{basin_sel}'.format(basin_sel=basin_sel)+save_ext_figs,\n",
    "                format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d984ad04",
   "metadata": {},
   "source": [
    "##### Performance diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d604bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig12,ax12 = plt.subplots(1,1,figsize=(12,8))\n",
    "SHIPS_plotting.make_performance_diagram_background(ax12)\n",
    "\n",
    "#ax12.errorbar(cm_ALL_PD_sel.reset_index()['SR'],cm_ALL_PD_sel.reset_index()['POD'],yerr=cm_ALL_yerr,xerr=cm_ALL_xerr,\n",
    " #           linestyle='none',linewidth=2,color='k')\n",
    "#sns.scatterplot(data=cm_ALL_PD_sel.reset_index(),x='SR',y='POD',hue='BASIN',ax=ax12,palette=sns.set_palette(pal_sel),\n",
    "  #              s=180,zorder=10)\n",
    "ax12.set_title('Classifying RI Cases, {solver}'.format(solver='RF'),fontsize=22)\n",
    "SHIPS_plotting.add_model_results(ax12,cm_ALL)\n",
    "fig12.savefig(save_dir+'figs/Performance_Diagram'+save_ext_figs,\n",
    "           format='png',dpi=250,bbox_inches='tight')\n",
    "plt.close('all')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b063318",
   "metadata": {},
   "source": [
    "#### Performance Diagram curves: PoD vs Success Ratio\n",
    "\n",
    "1. PoD vs Success Ratio curves.  Each fold shown separately, and then averaged across all folds.  Each basin will be separate.\n",
    "2. AUPD (area under performance diagram) scores. Calculated for each fold and shown as a swarm or box plot, all basins on one plot\n",
    "3. Max CSI. Calculated for each fold / basin and shown as swarm or box plot, all basins on one plot. \n",
    "4. CSI vs Bias.  Calculated for each fold / basin and shown as scatterplot, all basins on one plot. Also show mean across all folds. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e76fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_curves = SHIPS_ML_model_funcs.calculate_PD_curves(p_vs_r_ALL)\n",
    "fig15,ax15 = plt.subplots(1,1,figsize=(10,6))\n",
    "max_CSI_ind = p_vs_r_ALL.groupby(['BASIN','Fold'])[['CSI','Bias']].agg({'CSI':'max'}).reset_index()\n",
    "SHIPS_plotting.plot_basic_score_basin(ax15,max_CSI_ind,'CSI',False)\n",
    "ax15.set_title('Maximum CSI Scores for RI Cases, {solver}'.format(solver='RF'),fontsize=20)\n",
    "ax15.set_ylabel('Maximum CSI Score',fontsize=16)\n",
    "ax15.set_ylim([0,0.6])\n",
    "fig15.savefig(save_dir+'figs/Max_CSI_RI_vs_basin'+save_ext_figs,\n",
    "            format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e02a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.swarmplot(data=foo2.reset_index(),x='BASIN',y='CSI')\n",
    "fig30,ax30 = plt.subplots(1,1,figsize=(10,6))\n",
    "SHIPS_plotting.plot_CSI_vs_bias(p_vs_r_ALL,ax30)\n",
    "ax30.set_title('Bias at Maximum CSI for RI cases, {solver}'.format(solver='RF'),fontsize=21)\n",
    "fig30.savefig(save_dir+'figs/CSI_vs_bias_RI'+save_ext_figs,\n",
    "            format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4949e90d",
   "metadata": {},
   "source": [
    "##### Area under PD Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0351c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aupd_scores = SHIPS_ML_model_funcs.calc_AUPD(p_vs_r_ALL)\n",
    "aupd_plt = aupd_scores.reset_index().rename(columns={0:'AUPD'})\n",
    "fig14,ax14 = plt.subplots(1,1,figsize=(10,6))\n",
    "SHIPS_plotting.plot_basic_score_basin(ax14,aupd_plt,'AUPD',True)\n",
    "ax14.set_ylabel('Area Under PD Curve',fontsize=16)\n",
    "ax14.set_title('Area Under Performance Diagram, RI Cases, {solver}'.format(solver='RF'),fontsize=21)\n",
    "ax14.set_ylim([0,0.55])\n",
    "fig14.savefig(save_dir+'figs/AUPD_calculation_RI_cases'+save_ext_figs,\n",
    "            format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8247b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for basin_sel in BASIN_all:\n",
    "    fig23,ax23 = plt.subplots(1,1,figsize=(12,8))\n",
    "    SHIPS_plotting.make_performance_diagram_background(ax23)\n",
    "    SHIPS_plotting.plot_PD_curves(p_vs_r_ALL,ax23,basin_sel)\n",
    "    ax23.set_title('RI Cases, {basin_sel}, {solver}'.format(basin_sel=basin_sel,solver='RF'),fontsize=22)\n",
    "    f23_save = (save_dir+'figs/Performance_Diagram_CURVES_{basin_sel}'.format(basin_sel=basin_sel))\n",
    "    fig23.savefig(f23_save+save_ext_figs,\n",
    "                format=fig_format,dpi=300,bbox_inches='tight')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cdae43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SHIPS",
   "language": "python",
   "name": "ships"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
